{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_Object_Detection_v4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Koga-MD/DL-Tauopathies/blob/main/1_Object_Detection_v5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJn45Kfpw_VX"
      },
      "source": [
        "# Use this code when restarting the program. \"darknet\" folder should be removed before downloading YOLO from Github again.\n",
        "import shutil\n",
        "shutil.rmtree(\"/content/darknet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnSN0sSdmGD8"
      },
      "source": [
        "# To mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S5tdOv45haU"
      },
      "source": [
        "import cv2\n",
        "import shutil\n",
        "import os\n",
        "from google.colab import output\n",
        "import threading\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path\n",
        "from PIL import Image\n",
        "import sys\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hLnoq4oUnYB"
      },
      "source": [
        "# Download Darknet from Github\n",
        "os.chdir(\"/content\")\n",
        "!git clone https://github.com/AlexeyAB/darknet\n",
        "\n",
        "# For setting GPU\n",
        "%cd darknet\n",
        "!sed -i 's/GPU=0/GPU=1/g' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/g' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/g' Makefile\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/g' Makefile\n",
        "!cat Makefile\n",
        "!make\n",
        "\n",
        "!mkdir /content/darknet/drive\n",
        "!mkdir /content/darknet/drive/result\n",
        "!mkdir /content/darknet/drive/result2\n",
        "!mkdir /content/darknet/task1\n",
        "!mkdir /content/darknet/task1/backup\n",
        "!mkdir /content/darknet/task1/predict\n",
        "!mkdir /content/darknet/task1/result\n",
        "!mkdir /content/darknet/task1/test\n",
        "!mkdir /content/darknet/task1/data\n",
        "!mkdir /content/darknet/task1/train\n",
        "\n",
        "!cp /content/darknet/data/voc.names /content/darknet/task1/obj.names\n",
        "!cp /content/darknet/cfg/yolov3.cfg /content/darknet/task1/yolov3.cfg\n",
        "!cp \"/content/drive/My Drive/task1/process.py\" \"/content/darknet/process.py\"\n",
        "\n",
        "# Change the number of classes for training.\n",
        "!sed -i 's/classes= 20/classes= 5/g' cfg/voc.data\n",
        "!sed -i 's/\\/home\\/pjreddie\\/data\\/voc\\/train.txt/task1\\/train.txt/g' cfg/voc.data\n",
        "!sed -i 's/\\/home\\/pjreddie\\/data\\/voc\\/2007_test.txt/task1\\/test.txt/g' cfg/voc.data\n",
        "!sed -i 's/data\\/voc.names/task1\\/obj.names/g' cfg/voc.data\n",
        "!sed -i 's/\\/home\\/pjreddie\\/backup\\//backup/g' cfg/voc.data\n",
        "\n",
        "# Change class names\n",
        "!sed -i 's/aeroplane/NI/g' task1/obj.names\n",
        "!sed -i 's/bicycle/TA/g' task1/obj.names\n",
        "!sed -i 's/bird/NP/g' task1/obj.names\n",
        "!sed -i 's/boat/AP/g' task1/obj.names\n",
        "!sed -i 's/bottle/CB/g' task1/obj.names\n",
        "!sed -i '6,21d' task1/obj.names\n",
        "\n",
        "#Change parameters for training\n",
        "!sed -i 's/batch=1/#batch=1/g' task1/yolov3.cfg\n",
        "!sed -i 's/subdivisions=1/#subdivisions=1/g' task1/yolov3.cfg\n",
        "!sed -i 's/# batch=64/batch=128/g' task1/yolov3.cfg\n",
        "!sed -i 's/max_batches = 500200/max_batches = 10000/g' task1/yolov3.cfg\n",
        "!sed -i 's/classes=80/classes=5/g' task1/yolov3.cfg\n",
        "!sed -i 's/filters=255/filters=30/g' task1/yolov3.cfg\n",
        "!sed -i 's/# #subdivisions=16/subdivisions=32/g' task1/yolov3.cfg\n",
        "\n",
        "!cat task1/yolov3.cfg\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZTxLtpMfZI1"
      },
      "source": [
        "# Prepare training dataset\n",
        "# Copy Training data from Google Drive\n",
        "!cp \"/content/drive/My Drive/task1/data/Data.zip\" \"/content/darknet/task1/data/Data.zip\"\n",
        "\n",
        "# Unzip folder for training images\n",
        "os.chdir(\"/content/darknet/task1/data\")\n",
        "!unzip \"/content/darknet/task1/data/Data.zip\"\n",
        "os.remove(\"/content/darknet/task1/data/Data.zip\")\n",
        "\n",
        "os.chdir(\"/content/darknet\")\n",
        "!wget https://pjreddie.com/media/files/darknet53.conv.74  # download darknet53.conv.74 from URL to content/darknet\n",
        "\n",
        "# Split dataset into training and test sets (default = 8:2)\n",
        "!chmod 755 process.py\n",
        "!python process.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHfc4chpVSXI"
      },
      "source": [
        "# Train the model\n",
        "# Automatically clear output and save the log and chart files\n",
        " \n",
        "times = []\n",
        "for y in range(86400):\n",
        "    if y %60==0:\n",
        "      times.append(y)\n",
        "    else:\n",
        "      continue\n",
        "def gfg():\n",
        "    output.clear()\n",
        "\n",
        "for x in range(len(times)):\n",
        "    timer = threading.Timer(times[x],gfg)\n",
        "    timer.start()\n",
        "\n",
        "timess = []\n",
        "for z in range(86400):\n",
        "    if z %600==0:\n",
        "      timess.append(z)\n",
        "    else:\n",
        "      continue\n",
        "def asave():\n",
        "    !cp \"/content/darknet/Chartlog.txt\" \"/content/drive/My Drive/task1/Log.txt\"\n",
        "    !cp \"/content/darknet/chart.png\" \"/content/drive/My Drive/task1/Chart.png\" \n",
        "    !cp \"/content/darknet/backup/yolov3_best.weights\" \"/content/drive/My Drive/task1/Training-best.weights\" \n",
        "\n",
        "for x in range(len(timess)):\n",
        "    timers = threading.Timer(timess[x],asave)\n",
        "    timers.start()\n",
        "\n",
        "!./darknet detector train cfg/voc.data task1/yolov3.cfg /content/darknet/darknet53.conv.74 -map >> Chartlog.txt -dont_show"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re44LVCbVs9j"
      },
      "source": [
        "# Tuned models and image dataset are available at Zenodo (10.5281/zenodo.5082081)\n",
        "# Before using the weight, copy the best weight from the Google Drive\n",
        "!cp \"/content/drive/MyDrive/task1/Model1.weights\" \"/content/darknet/backup/yolov3_best.weights\"\n",
        "\n",
        "# Unzip test files\n",
        "shutil.rmtree(\"/content/darknet/task1/test/\")\n",
        "!mkdir /content/darknet/task1/test\n",
        "!cp \"/content/drive/MyDrive/task1/Test.zip\" \"/content/darknet/task1/test/Test.zip\"\n",
        "os.chdir(\"/content/darknet/task1/test\")\n",
        "\n",
        "!unzip \"/content/darknet/task1/test/Test.zip\"\n",
        "os.remove(\"/content/darknet/task1/test/Test.zip\")\n",
        "\n",
        "# Rename files in test folder\n",
        "with open('/content/darknet/task1/CaseList.txt', 'w') as f:\n",
        "  print(\"Test-Image\", 'Test ID', file=f)\n",
        "\n",
        "files = sorted(glob.glob('/content/darknet/task1/test/*'))\n",
        "\n",
        "for i, f in enumerate(files):\n",
        "    ftitle, fext = os.path.splitext(f)\n",
        "    os.rename(f, ftitle[:-9] + 'Test' + '{0:03d}'.format(i+1) + fext)\n",
        "    with open('/content/darknet/task1/CaseList.txt', 'a') as f:\n",
        "      print(ftitle[-9:], 'Test' + '{0:03d}'.format(i+1), file=f)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXTipMWRWbeJ"
      },
      "source": [
        "# Run Object detection for test images\n",
        "\n",
        "with open('/content/darknet/task1/Result.txt', 'w') as f:\n",
        "      print(\"Case-ID\", \"TA\", \"AP\", \"CB\", \"NI\", \"NP\", file=f)\n",
        "\n",
        "path, dirs, files = next(os.walk(\"/content/darknet/task1/test\"))\n",
        "fnum = len(files)\n",
        "\n",
        "for x in range(fnum):\n",
        "    PATH = \"/content/darknet/task1/test/Test\"+str(x+1+0).zfill(3)+\".jpg\"\n",
        "    fname = str(PATH[-11:-4])\n",
        "    os.chdir(\"/content/darknet\")\n",
        "    shutil.rmtree(\"/content/darknet/task1/predict\")\n",
        "    os.mkdir(\"/content/darknet/task1/predict\")\n",
        "    shutil.rmtree(\"/content/darknet/task1/result\")\n",
        "    os.mkdir(\"/content/darknet/task1/result\")\n",
        "    \n",
        "    im = Image.open(PATH)\n",
        "    height = 500\n",
        "    width = 500\n",
        "    ncol = im.size[0]//height\n",
        "    nrow = im.size[1]//width\n",
        "    ntile = ncol * nrow\n",
        "    # Spilt tiles from the prediction image\n",
        "    def ImgSplit(im):\n",
        "        for h1 in range(nrow):\n",
        "            for w1 in range(ncol):\n",
        "                w2 = w1 * height\n",
        "                h2 = h1 * width\n",
        "                print(w2, h2, width + w2, height + h2)\n",
        "                yield im.crop((w2, h2, width + w2, height + h2))\n",
        "\n",
        "    if __name__ == '__main__':\n",
        "        # Open image file\n",
        "        im = Image.open(PATH)\n",
        "        for number, ig in enumerate(ImgSplit(im), 1):\n",
        "            ig.save(\"/content/darknet/task1/predict/test%03d.jpg\" % number, \"JPEG\")\n",
        "\n",
        "    def display_image(file_path = './predictions.jpg'): \n",
        "        fig,ax = plt.subplots()\n",
        "        ax.tick_params(labelbottom=\"off\",bottom=\"off\")\n",
        "        ax.tick_params(labelleft=\"off\",left=\"off\")\n",
        "        ax.set_xticklabels([]) \n",
        "        ax.axis('off')\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "          img = cv2.imread(file_path)\n",
        "          show_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n",
        "          plt.imshow(show_img)\n",
        "\n",
        "    NI=[]\n",
        "    TA=[]\n",
        "    NP=[]\n",
        "    AP=[]  \n",
        "    CB=[]\n",
        "    RF=[]\n",
        "    Count=[]\n",
        "\n",
        "    for i in range(1, ntile + 1):\n",
        "        path1=\"/content/darknet/task1/predict/test\"+str(i).zfill(3)+\".jpg\"\n",
        "        path2=\"/content/darknet/task1/predict/test.jpg\"\n",
        "        os.rename(path1, path2)\n",
        "        !./darknet detector test cfg/voc.data /content/darknet/task1/yolov3.cfg /content/darknet/backup/yolov3_best.weights /content/darknet/task1/predict/test.jpg -dont_show -out myfile  > /content/darknet/task1/predict/result.txt\n",
        "        os.rename(path2, path1)\n",
        "        \n",
        "\n",
        "    # Show the result based on result.txt\n",
        "        with open(\"/content/darknet/task1/predict/result.txt\", 'r') as f:\n",
        "            lines  = [line.rstrip(\"\\n\") for line in f]\n",
        "            prev_line = \"\"\n",
        "            NIsub=[]\n",
        "            TAsub=[]\n",
        "            NPsub=[]\n",
        "            APsub=[]  \n",
        "            CBsub=[]\n",
        "            for line in lines:\n",
        "                args = line.split(' ')\n",
        "                if args[0]==\"NI:\" :\n",
        "                  NI.append(int(args[1][:-1]))\n",
        "                  NIsub.append(int(args[1][:-1]))\n",
        "                if args[0]==\"TA:\" :\n",
        "                  TA.append(int(args[1][:-1]))\n",
        "                  TAsub.append(int(args[1][:-1]))\n",
        "                if args[0]==\"NP:\" :\n",
        "                  NP.append(int(args[1][:-1]))\n",
        "                  NPsub.append(int(args[1][:-1]))\n",
        "                if args[0]==\"AP:\" :\n",
        "                  AP.append(int(args[1][:-1]))\n",
        "                  APsub.append(int(args[1][:-1]))\n",
        "                if args[0]==\"CB:\" :\n",
        "                  CB.append(int(args[1][:-1]))\n",
        "                  CBsub.append(int(args[1][:-1]))\n",
        "        if len(NIsub)>0 or len(TAsub)>0 or len(NPsub)>0 or len(APsub)>0 or len(CBsub)>0:\n",
        "          Count.append(i)\n",
        "              \n",
        "        path3=\"/content/darknet/predictions.jpg\"\n",
        "        path4=\"/content/darknet/task1/result/predicted\"+str(i).zfill(3)+\".jpg\"\n",
        "        os.rename(path3, path4) \n",
        "\n",
        "    # Combine all predicted images into one large image.\n",
        "    # Sort predicted images by name\n",
        "    list_im = sorted(os.listdir(path='/content/darknet/task1/result'))\n",
        "    os.chdir(\"/content/darknet/task1/result/\")\n",
        "    images = [Image.open(x) for x in list_im]\n",
        "    new_im = Image.new('RGB',(height*ncol, width*nrow))\n",
        "    x_offset = 0\n",
        "    for i in range(nrow+1):\n",
        "        x_offset = 0\n",
        "        for IM in images[(i-1)*ncol:i*ncol]:\n",
        "            new_im.paste(IM,(x_offset,height*(i-1)))\n",
        "            x_offset += IM.size[0]\n",
        "    new_im.save('Result.jpg')\n",
        "\n",
        "    # Use Result.txt multiple times\n",
        "    !cp \"/content/darknet/task1/Result.txt\" \"/content/darknet/task1/result/Result.txt\"\n",
        "    \n",
        "    with open('Result.txt', 'a') as f:\n",
        "      print(fname, len(TA), len(AP), len(CB), len(NI), len(NP), file=f)\n",
        "    \n",
        "    shutil.rmtree(\"/content/darknet/drive/result\")\n",
        "    shutil.copytree(\"/content/darknet/task1/result\", \"/content/darknet/drive/result\")\n",
        "\n",
        "    # Keep a copy of Result jpeg\n",
        "    !cp \"/content/darknet/drive/result/Result.jpg\" \"/content/darknet/drive/result2/Result.jpg\"  \n",
        "    old=\"/content/darknet/drive/result2/Result.jpg\"\n",
        "    new=\"/content/darknet/drive/result2/res_\"+fname+\".jpg\"\n",
        "    os.rename(old, new) \n",
        "\n",
        "    # Keep a copy of Result text\n",
        "    !cp \"/content/darknet/drive/result/Result.txt\" \"/content/darknet/drive/result2/Result.txt\"  \n",
        "    old=\"/content/darknet/drive/result2/Result.txt\"\n",
        "    new=\"/content/darknet/drive/result2/res_\"+fname+\".txt\"\n",
        "    os.rename(old, new) \n",
        "    !cp \"/content/darknet/task1/result/Result.txt\" \"/content/darknet/task1/Result.txt\"\n",
        "\n",
        "!cp \"/content/darknet/task1/CaseList.txt\" \"/content/darknet/drive/result2/CaseList.txt\"\n",
        "!cp \"/content/darknet/task1/Result.txt\" \"/content/darknet/drive/result2/Result.txt\"    \n",
        "\n",
        "### Convert Result.txt & CaseList.txt to FinalResult.csv\n",
        "resultfilename = []\n",
        "with open('/content/darknet/task1/Result.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        resultfilename.append(line.split())\n",
        "\n",
        "caselist = []\n",
        "with open('/content/darknet/task1/CaseList.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        caselist.append(line.split())\n",
        "\n",
        "# Get 1st row and other keys\n",
        "resultcolumnname = resultfilename.pop(0)\n",
        "rc = [\"MC_\" + i for i in resultcolumnname[1:]]\n",
        "rc2 = [\"CN_\" + i for i in resultcolumnname[1:]]\n",
        "rc3 = [\"SF_\" + i for i in resultcolumnname[1:]]\n",
        "rc = rc + rc2 + rc3\n",
        "\n",
        "# Unify values every 3 list\n",
        "resultkeyandvalue = resultfilename\n",
        "resultkeyandvalue = np.array([resultkeyandvalue[i:i + 3] for i in range(0,len(resultkeyandvalue), 3)])\n",
        "# Get 1st column and change keys' name\n",
        "resultkeys = list(resultkeyandvalue[:,0,0])\n",
        "for i in range(len(caselist)):\n",
        "    sub = {caselist[i][1]: caselist[i][0]}\n",
        "    resultkeys = [sub.get(x, x).rstrip(\"DJI\") for x in resultkeys]\n",
        "\n",
        "# Delete picture titles and squeeze values, then change data form to list\n",
        "resultvalues = np.delete(resultkeyandvalue, 0, axis=2)\n",
        "resultvalues = resultvalues.reshape(len(resultvalues), -1)\n",
        "resultvalues = resultvalues.tolist()\n",
        "\n",
        "# Make dataframe\n",
        "df = pd.DataFrame(resultvalues,\n",
        "                  index=resultkeys,\n",
        "                  columns=rc)\n",
        "df.index.name = \"Case-ID\"\n",
        "\n",
        "df.to_csv(\"FinalResult.csv\", sep=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Deai-Kq1k4yJ"
      },
      "source": [
        "**Decision Tree & Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSjenGq9k3pc"
      },
      "source": [
        "#####For Manuscript \n",
        "# Import our dataset for making Random Forest\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/task1/RF-Model1.csv\")\n",
        "\n",
        "pilot = sklearn.utils.Bunch()\n",
        "pilot['target'] = df['Dx']\n",
        "pilot['data'] = df.iloc[:, 2:17]\n",
        "label = df.columns.values\n",
        "names = label[2:17]\n",
        "classes = ['AD','CBD','PiD','PSP']\n",
        "\n",
        "# Random Forest\n",
        "from sklearn.model_selection import train_test_split\n",
        "list_train = []\n",
        "list_test = []\n",
        "for i in range (30):\n",
        "  x_train, x_test, t_train, t_test = train_test_split(\n",
        "      pilot['data'],pilot['target'], random_state=i)\n",
        "\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  RF = RandomForestClassifier(n_estimators=500)\n",
        "  RF.fit(x_train, t_train)\n",
        "  Y_pred = RF.predict(x_test)\n",
        "  RF.score(x_train, t_train)\n",
        "  Train_score = round(RF.score(x_train, t_train), 3)\n",
        "  Test_score = round(RF.score(x_test, t_test), 3)\n",
        "  list_train.append(Train_score)\n",
        "  list_test.append(Test_score)\n",
        "  print(i, \"Training Score:\", Train_score)\n",
        "  print(i+1, \"Test Score:\", Test_score)\n",
        "print(\"Average Train Score:\", sum(list_train)/len(list_train))\n",
        "print(\"Average Test Score:\", round(sum(list_test)/len(list_test),3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrwrQmBzlhtJ"
      },
      "source": [
        "## Hold-out dataset \n",
        "# Import our hold-out dataset for diagnosing\n",
        "df2 = pd.read_csv(\"/content/drive/MyDrive/task1/HO-CP13-Model1.csv\")\n",
        "\n",
        "x_test2 = df2.iloc[:, 2:17]\n",
        "t_test2 = df2['Dx']\n",
        "Y_pred = RF.predict(x_test2)\n",
        "print(\"Predicted diagnoses are as follows:\", Y_pred)\n",
        "print(Y_pred)\n",
        "list_train = []\n",
        "list_test = []\n",
        "for i in range (30):\n",
        "  RF = RandomForestClassifier(n_estimators=500)\n",
        "  RF.fit(x_train, t_train)\n",
        "  Test_score = round(RF.score(x_test2, t_test2), 3)\n",
        "  list_test.append(Test_score)\n",
        "  print(\"Test\", i+1, \": Test Score =\", Test_score)\n",
        "print(\"Average Test Score:\", round(sum(list_test)/len(list_test),3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7xm_o-ul1EM"
      },
      "source": [
        "# Import csv file for making diagnoses\n",
        "df3 = pd.read_csv(\"/content/darknet/task1/result/FinalResult.csv\")\n",
        "\n",
        "# Import our dataset for making Random Forest\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/task1/RF-Model1.csv\")\n",
        "\n",
        "pilot = sklearn.utils.Bunch()\n",
        "# 'Dx' to 'target'\n",
        "pilot['target'] = df['Dx']\n",
        "# Predictor into 'data'\n",
        "pilot['data'] = df.iloc[:, 2:17]\n",
        "\n",
        "# Name class\n",
        "label = df.columns.values\n",
        "names = label[2:17]\n",
        "classes = ['AD','CBD','PiD','PSP']\n",
        "\n",
        "# Random Forest\n",
        "# Splits the dataset into train and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "list_train = []\n",
        "list_test = []\n",
        "for i in range (30):\n",
        "  x_train, x_test, t_train, t_test = train_test_split(\n",
        "      pilot['data'],pilot['target'], random_state=i)\n",
        "\n",
        "  # Random Forest\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "  RF = RandomForestClassifier(n_estimators=500)\n",
        "  RF.fit(x_train, t_train)\n",
        "  Y_pred = RF.predict(x_test)\n",
        "  RF.score(x_train, t_train)\n",
        "  Train_score = round(RF.score(x_train, t_train), 3)\n",
        "  Test_score = round(RF.score(x_test, t_test), 3)\n",
        "  list_train.append(Train_score)\n",
        "  list_test.append(Test_score)\n",
        "\n",
        "## Predicted diagnoses are given. \n",
        "x_test3 = df3.iloc[:, 1:16]\n",
        "Y_pred = RF.predict(x_test3)\n",
        "print(\"Predicted diagnoses are as follows:\\n\", Y_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}